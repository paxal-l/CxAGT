# Simple Context Augmentor (CxAGT)
CxAGT - Experimental LLM memory wrapper for context, memory logging and embedding-based retrieval around local models (Ollama). Status: experimental / learning project.

![CxAGT architecture](docs/cxagt_simple_diagram.png)

What CxAGT does:
CxAGT is a lightweight proxy or Ollama wrapper that sits in front of a local Ollama instance and augments chat requests with context derived from prior interactions.

CxAGT is also Open WebUi compatible, which means you can add CxAGT as a Ollama API connection using the proxy adress http://localhost:11400.

Why using CxAGT?
If you want a super lightweight and transparent long term memory and context augmenter for LLMs.

For each user request:
The request is forwarded through CxAGT using the Ollama-compatible /api/chat interface.
A compact, single-line summary of the interaction is generated by a small auxiliary language model (SCRIBE) and appended to a simple local memory file.
Previously stored memory lines are embedded using a sentence-transformer model and compared semantically against the current user input.
A small set of the most relevant memory entries is selected and injected into the prompt before the request is sent to the language model.

Requests are routed to a primary or fallback Ollama backend depending on availability.
Memory is stored as human readable text and retrieved using vector similarity at request time. Context injection happens at the prompt level and is bounded by configurable similarity thresholds and limits.
CxAGT exposes standard Ollama endpoints for compatibility with existing tools, along with a small set of development endpoints for inspecting memory and retrieval behavior.
